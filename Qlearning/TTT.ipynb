{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup TTT Board\n",
    "It might be more simplified.\n",
    "If you want computing efficiency, you can consider rotating/mirroring the board but I just don't do it cause this program is to understand only the Reinforcement Learning logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.10.14)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import random\n",
    "\n",
    "# POS State\n",
    "EMPTY = 0\n",
    "PLAYER_X = 1\n",
    "PLAYER_O = -1\n",
    "MARKS = {PLAYER_X: \"X\", PLAYER_O: \"O\", EMPTY: \" \"}\n",
    "DRAW = 2\n",
    "\n",
    "class TTTBoard:\n",
    "    \n",
    "    def __init__(self, board=None):\n",
    "        if board is None:\n",
    "            self.board = [EMPTY] * 9\n",
    "        else:\n",
    "            self.board = board\n",
    "        self.winner = None\n",
    "        self.invalid_move = None\n",
    "    \n",
    "    def get_possible_pos(self):\n",
    "        return [i for i, cell in enumerate(self.board) if cell == EMPTY]\n",
    "    \n",
    "    def pygame_init(self):\n",
    "        pygame.init()\n",
    "        self.screen = pygame.display.set_mode((300, 300))\n",
    "        self.font = pygame.font.Font(None, 100)\n",
    "        pygame.display.set_caption(\"Tic Tac Toe\")\n",
    "        self.pygame_render(self.board)\n",
    "    \n",
    "    def pygame_render(self, board):\n",
    "        WHITE = (255, 255, 255)\n",
    "        BLACK = (0, 0, 0)\n",
    "        RED = (255, 0, 0, 150)\n",
    "        self.screen.fill(WHITE)\n",
    "        \n",
    "        for x in range(1, 3):\n",
    "            pygame.draw.line(self.screen, BLACK, (x * 100, 0), (x * 100, 300), 3)\n",
    "            pygame.draw.line(self.screen, BLACK, (0, x * 100), (300, x * 100), 3)\n",
    "            \n",
    "        for i in range(9):\n",
    "            x = i % 3\n",
    "            y = i // 3\n",
    "            if board[i] == PLAYER_X:\n",
    "                text = self.font.render('X', True, BLACK)\n",
    "                self.screen.blit(text, (x * 100 + 25, y * 100 + 15))\n",
    "            elif board[i] == PLAYER_O:\n",
    "                text = self.font.render('O', True, BLACK)\n",
    "                self.screen.blit(text, (x * 100 + 25, y * 100 + 15))\n",
    "            \n",
    "        if self.invalid_move is not None: \n",
    "            i = self.invalid_move\n",
    "            x = i % 3\n",
    "            y = i // 3\n",
    "            pygame.draw.rect(self.screen, RED, (x * 100, y * 100, 100, 100), 3)\n",
    "        \n",
    "        pygame.display.flip()\n",
    "\n",
    "    def check_winner(self):\n",
    "        win_cond = ((0, 1, 2), (3, 4, 5), (6, 7, 8), (0, 3, 6), (1, 4, 7), (2, 5, 8), (0, 4, 8), (2, 4, 6))\n",
    "        for each in win_cond:\n",
    "            if self.board[each[0]] == self.board[each[1]] == self.board[each[2]] and self.board[each[0]] != EMPTY:\n",
    "                self.winner = self.board[each[0]]\n",
    "                return self.winner\n",
    "        return None\n",
    "    \n",
    "    def check_draw(self):\n",
    "        if not any(cell == EMPTY for cell in self.board) and self.winner is None:\n",
    "            self.winner = DRAW\n",
    "            return DRAW\n",
    "        return None\n",
    "    \n",
    "    def move(self, pos, player):\n",
    "        if self.board[pos] == EMPTY:\n",
    "            self.board[pos] = player\n",
    "            self.invalid_move = None\n",
    "        else:\n",
    "            self.invalid_move = pos\n",
    "            self.winner = -1 * player\n",
    "        self.check_winner()\n",
    "        self.check_draw()\n",
    "    \n",
    "    def clone(self):\n",
    "        return TTTBoard(self.board.copy())\n",
    "\n",
    "    def switch_player(self):\n",
    "        if self.player_turn == PLAYER_X:\n",
    "            self.player_turn = PLAYER_O\n",
    "        else:\n",
    "            self.player_turn = PLAYER_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Game Organizer (it is like judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTT_GameOrganizer:\n",
    "\n",
    "    act_turn = 0\n",
    "    winner = None\n",
    "    \n",
    "    def __init__(self, px, po, nplay=1, showBoard=True, showResult=True, stat=100):\n",
    "        self.player_x = px\n",
    "        self.player_o = po\n",
    "        self.nwon = {px.myturn: 0, po.myturn: 0, DRAW: 0}\n",
    "        self.nplay = nplay\n",
    "        self.players = (self.player_x, self.player_o)\n",
    "        self.board = None\n",
    "        self.disp = showBoard\n",
    "        self.showResult = showResult\n",
    "        self.player_turn = self.players[random.randrange(2)]\n",
    "        self.nplayed = 0\n",
    "        self.stat = stat\n",
    "    \n",
    "    def progress(self):\n",
    "        while self.nplayed < self.nplay:\n",
    "            self.board = TTTBoard()\n",
    "            if self.disp:\n",
    "                self.board.pygame_init()\n",
    "            while self.board.winner is None:\n",
    "                act = self.player_turn.act(self.board)\n",
    "                self.board.move(act, self.player_turn.myturn)\n",
    "                if self.disp: self.board.pygame_render(self.board.board)\n",
    "               \n",
    "                if self.board.winner is not None:\n",
    "                    for i in self.players:\n",
    "                        i.getGameResult(self.board) \n",
    "                    if self.board.winner == DRAW:\n",
    "                        if self.showResult: print(\"Draw Game\")\n",
    "                    elif self.board.winner == self.player_turn.myturn:\n",
    "                        out = \"Winner : \" + self.player_turn.name\n",
    "                        if self.showResult: print(out)\n",
    "                    else:\n",
    "                        print(\"Invalid Move!\")\n",
    "                    self.nwon[self.board.winner] += 1\n",
    "                else:\n",
    "                    self.switch_player()\n",
    "                    self.player_turn.getGameResult(self.board)\n",
    "\n",
    "            self.nplayed += 1\n",
    "            if self.nplayed % self.stat == 0 or self.nplayed == self.nplay:\n",
    "                print(f\"{self.player_x.name}:{self.nwon[self.player_x.myturn]}, {self.player_o.name}:{self.nwon[self.player_o.myturn]}, DRAW:{self.nwon[DRAW]}\")\n",
    "                if self.disp:pygame.quit()\n",
    "                    \n",
    "    def switch_player(self):\n",
    "        if self.player_turn == self.player_x:\n",
    "            self.player_turn = self.player_o\n",
    "        else:\n",
    "            self.player_turn = self.player_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random player and Human Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "class PlayerRandom:\n",
    "    def __init__(self, turn):\n",
    "        self.name = \"Random\"\n",
    "        self.myturn = turn\n",
    "        \n",
    "    def act(self, board):\n",
    "        acts = board.get_possible_pos()\n",
    "        i = random.randrange(len(acts))\n",
    "        return acts[i]\n",
    "    \n",
    "    def getGameResult(self, board):\n",
    "        pass\n",
    "\n",
    "class PlayerHuman:\n",
    "    def __init__(self, turn):\n",
    "        self.name = \"Human\"\n",
    "        self.myturn = turn\n",
    "        \n",
    "    def act(self, board):\n",
    "        valid = False\n",
    "        while not valid:\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    pygame.quit()\n",
    "                    sys.exit()\n",
    "                elif event.type == pygame.MOUSEBUTTONDOWN:\n",
    "                    x, y = event.pos\n",
    "                    row = y // 100\n",
    "                    col = x // 100\n",
    "                    act = row * 3 + col\n",
    "                    if act >= 0 and act < 9 and board.board[act] == EMPTY:\n",
    "                        valid = True\n",
    "                        return act\n",
    "                    else:\n",
    "                        print(\"That is not a valid move! Please try again.\")\n",
    "    \n",
    "    def getGameResult(self, board):\n",
    "        if board.winner is not None and board.winner != self.myturn and board.winner != DRAW:\n",
    "            print(\"I lost...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msy-t\\anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def Human_vs_Random():\n",
    "    \n",
    "    p1=PlayerHuman(PLAYER_X)\n",
    "    p2=PlayerRandom(PLAYER_O)\n",
    "    game=TTT_GameOrganizer(p1,p2)\n",
    "    game.progress()\n",
    "\n",
    "Human_vs_Random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Random Player\n",
    "Alpha Random to check winnable next hand if exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerAlphaRandom:\n",
    "    \n",
    "    \n",
    "    def __init__(self,turn,name=\"AlphaRandom\"):\n",
    "        self.name=name\n",
    "        self.myturn=turn\n",
    "        \n",
    "    def getGameResult(self,winner):\n",
    "        pass\n",
    "        \n",
    "    def act(self,board):\n",
    "        acts=board.get_possible_pos()\n",
    "        #see only next winnable act\n",
    "        for act in acts:\n",
    "            tempboard=board.clone()\n",
    "            tempboard.move(act,self.myturn)\n",
    "            # check if win\n",
    "            if tempboard.winner==self.myturn:\n",
    "                #print (\"Check mate\")\n",
    "                return act\n",
    "        i=random.randrange(len(acts))\n",
    "        return acts[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montecarlo Player\n",
    "Randomly (with checking winnable hand.) play till game end for N times of each next hand, then decide the most probably winnable hand.\n",
    "If N is more than 100, it is almost not defeatable.\n",
    "You can improve it to MCST Player, but TTT doesn't need such computing efficiency..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerMC:\n",
    "    def __init__(self,turn,name=\"MC\"):\n",
    "        self.name=name\n",
    "        self.myturn=turn\n",
    "    \n",
    "    def getGameResult(self,winner):\n",
    "        pass\n",
    "        \n",
    "    def win_or_rand(self,board,turn):\n",
    "        acts=board.get_possible_pos()\n",
    "        #see only next winnable act\n",
    "        for act in acts:\n",
    "            tempboard=board.clone()\n",
    "            tempboard.move(act,turn)\n",
    "            # check if win\n",
    "            if tempboard.winner==turn:\n",
    "                return act\n",
    "        i=random.randrange(len(acts))\n",
    "        return acts[i]\n",
    "           \n",
    "    def trial(self,score,board,act):\n",
    "        tempboard=board.clone()\n",
    "        tempboard.move(act,self.myturn)\n",
    "        tempturn=self.myturn\n",
    "        while tempboard.winner is None:\n",
    "            tempturn=tempturn*-1\n",
    "            tempboard.move(self.win_or_rand(tempboard,tempturn),tempturn)\n",
    "        \n",
    "        if tempboard.winner==self.myturn:\n",
    "            score[act]+=1\n",
    "        elif tempboard.winner==DRAW:\n",
    "            pass\n",
    "        else:\n",
    "            score[act]-=1\n",
    "\n",
    "        \n",
    "    def getGameResult(self,board):\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def act(self,board):\n",
    "        acts=board.get_possible_pos()\n",
    "        scores={}\n",
    "        n=50\n",
    "        for act in acts:\n",
    "            scores[act]=0\n",
    "            for i in range(n):\n",
    "                #print(\"Try\"+str(i))\n",
    "                self.trial(scores,board,act)\n",
    "            \n",
    "            #print(scores)\n",
    "            scores[act]/=n\n",
    "        \n",
    "        max_score=max(scores.values())\n",
    "        for act, v in scores.items():\n",
    "            if v == max_score:\n",
    "                #print(str(act)+\"=\"+str(v))\n",
    "                return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draw Game\n",
      "Draw Game\n",
      "Winner : M2\n",
      "Draw Game\n",
      "Draw Game\n",
      "Draw Game\n",
      "Winner : M2\n",
      "Draw Game\n",
      "Draw Game\n",
      "Draw Game\n",
      "M1:0, M2:2, DRAW:8\n"
     ]
    }
   ],
   "source": [
    "#p1=PlayerAlphaRandom(PLAYER_X)\n",
    "p1=PlayerMC(PLAYER_X,\"M1\")\n",
    "p2=PlayerMC(PLAYER_O,\"M2\")\n",
    "#p2=PlayerHuman(PLAYER_O)\n",
    "game=TTT_GameOrganizer(p1,p2,10,False)\n",
    "game.progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning Player (Look up Q(s,a) table)\n",
    "\n",
    "Q(s,a) = Q(s,a) + alpha (reward + gammma* max(Q(s',a')- Q(s,a))\n",
    "The struggled points are ...\n",
    "- epliron to be shurinked to zero considering try counts\n",
    "- need to learn Q every step, not only at the game end\n",
    "- if at the game end (=terminal state) like DRAW,WIN, maxQ is zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PlayerQL:\n",
    "    def __init__(self,turn,name=\"QL\",e=0.2,alpha=0.3):\n",
    "        self.name=name\n",
    "        self.myturn=turn\n",
    "        self.q={} #set of s,a\n",
    "        self.e=e\n",
    "        self.alpha=alpha\n",
    "        self.gamma=0.9\n",
    "        self.last_move=None\n",
    "        self.last_board=None\n",
    "        self.totalgamecount=0\n",
    "        \n",
    "    \n",
    "    def policy(self,board):\n",
    "        self.last_board=board.clone()\n",
    "        acts=board.get_possible_pos()\n",
    "        #Explore sometimes\n",
    "        if random.random() < (self.e/(self.totalgamecount//10000+1)):\n",
    "                i=random.randrange(len(acts))\n",
    "                return acts[i]\n",
    "        qs = [self.getQ(tuple(self.last_board.board),act) for act in acts]\n",
    "        maxQ= max(qs)\n",
    "\n",
    "        if qs.count(maxQ) > 1:\n",
    "            # more than 1 best option; choose among them randomly\n",
    "            best_options = [i for i in range(len(acts)) if qs[i] == maxQ]\n",
    "            i = random.choice(best_options)\n",
    "        else:\n",
    "            i = qs.index(maxQ)\n",
    "\n",
    "        self.last_move = acts[i]\n",
    "        return acts[i]\n",
    "    \n",
    "    def getQ(self, state, act):\n",
    "        # encourage exploration; \"optimistic\" 1.0 initial values\n",
    "        if self.q.get((state, act)) is None:\n",
    "            self.q[(state, act)] = 1\n",
    "        return self.q.get((state, act))\n",
    "    \n",
    "    def getGameResult(self,board):\n",
    "        r=0\n",
    "        if self.last_move is not None:\n",
    "            if board.winner is None:\n",
    "                self.learn(self.last_board,self.last_move, 0, board)\n",
    "                pass\n",
    "            else:\n",
    "                if board.winner == self.myturn:\n",
    "                    self.learn(self.last_board,self.last_move, 1, board)\n",
    "                elif board.winner !=DRAW:\n",
    "                    self.learn(self.last_board,self.last_move, -1, board)\n",
    "                else:\n",
    "                    self.learn(self.last_board,self.last_move, 0, board)\n",
    "                self.totalgamecount+=1\n",
    "                self.last_move=None\n",
    "                self.last_board=None\n",
    "\n",
    "    def learn(self,s,a,r,fs):\n",
    "        pQ=self.getQ(tuple(s.board),a)\n",
    "        if fs.winner is not None:\n",
    "            maxQnew=0\n",
    "        else:\n",
    "            maxQnew=max([self.getQ(tuple(fs.board),act) for act in fs.get_possible_pos()])\n",
    "        self.q[(tuple(s.board),a)]=pQ+self.alpha*((r+self.gamma*maxQnew)-pQ)\n",
    "        #print (str(s.board)+\"with \"+str(a)+\" is updated from \"+str(pQ)+\" refs MAXQ=\"+str(maxQnew)+\":\"+str(r))\n",
    "        #print(self.q)\n",
    "\n",
    "    \n",
    "    def act(self,board):\n",
    "        return self.policy(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Q by themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QL1:4273, QL2:4542, DRAW:1185\n",
      "QL1:8316, QL2:8456, DRAW:3228\n",
      "QL1:11878, QL2:11977, DRAW:6145\n",
      "QL1:14227, QL2:14219, DRAW:11554\n",
      "QL1:15175, QL2:15112, DRAW:19713\n",
      "QL1:15657, QL2:15628, DRAW:28715\n",
      "QL1:16104, QL2:16037, DRAW:37859\n",
      "QL1:16473, QL2:16399, DRAW:47128\n",
      "QL1:16775, QL2:16712, DRAW:56513\n",
      "QL1:17078, QL2:17048, DRAW:65874\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pQ=PlayerQL(PLAYER_O,\"QL1\")\n",
    "p2=PlayerQL(PLAYER_X,\"QL2\")\n",
    "game=TTT_GameOrganizer(pQ,p2,100000,False,False,10000)\n",
    "game.progress()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QL1:0, M1:0, DRAW:10\n",
      "QL1:0, M1:0, DRAW:20\n",
      "QL1:0, M1:0, DRAW:30\n",
      "QL1:0, M1:0, DRAW:40\n",
      "QL1:0, M1:0, DRAW:50\n",
      "QL1:0, M1:0, DRAW:60\n",
      "QL1:0, M1:0, DRAW:70\n",
      "QL1:0, M1:0, DRAW:80\n",
      "QL1:0, M1:0, DRAW:90\n",
      "QL1:0, M1:0, DRAW:100\n"
     ]
    }
   ],
   "source": [
    "pQ.e=0\n",
    "p2=PlayerMC(PLAYER_X,\"M1\")\n",
    "game=TTT_GameOrganizer(pQ,p2,100,False,False,10)\n",
    "game.progress()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now time to play with Computer\n",
    "Human misses but computer never... It's wasting time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draw Game\n",
      "Draw Game\n",
      "Draw Game\n",
      "Draw Game\n",
      "Draw Game\n",
      "I lost...\n",
      "Winner : M1\n",
      "I lost...\n",
      "Winner : M1\n",
      "Draw Game\n",
      "Draw Game\n",
      "Draw Game\n",
      "Draw Game\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "p1.e=0\n",
    "p2=PlayerHuman(PLAYER_O)\n",
    "game=TTT_GameOrganizer(p1,p2,20)\n",
    "game.progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q network Player\n",
    "Q-Learning is to store Q(s,a) table but it is memory consuming... and can't use for large space problems..\n",
    "So Deep Q Network is Q(s) to output best Action. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "\n",
    "from chainer import Function, gradient_check, Variable, optimizers, serializers, utils\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import numpy as np\n",
    "from chainer import computational_graph as c\n",
    "\n",
    "# Network definition\n",
    "class MLP(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_in, n_units, n_out):\n",
    "        super(MLP, self).__init__(\n",
    "            l1=L.Linear(n_in, n_units),  # first layer\n",
    "            l2=L.Linear(n_units, n_units),  # second layer\n",
    "            l3=L.Linear(n_units, n_units),  # Third layer\n",
    "            l4=L.Linear(n_units, n_out),  # output layer\n",
    "        )\n",
    "\n",
    "    def __call__(self, x, t=None, train=False):\n",
    "        h = F.leaky_relu(self.l1(x))\n",
    "        h = F.leaky_relu(self.l2(h))\n",
    "        h = F.leaky_relu(self.l3(h))\n",
    "        h = self.l4(h)\n",
    "\n",
    "        if train:\n",
    "            return F.mean_squared_error(h,t)\n",
    "        else:\n",
    "            return h\n",
    "\n",
    "    def get(self,x):\n",
    "        # input x as float, output float\n",
    "        return self.predict(Variable(np.array([x]).astype(np.float32).reshape(1,1))).data[0][0]\n",
    "\n",
    "\n",
    "class DQNPlayer:\n",
    "    def __init__(self, turn,name=\"DQN\",e=1,dispPred=False):\n",
    "        self.name=name\n",
    "        self.myturn=turn\n",
    "        self.model = MLP(9, 162,9)\n",
    "        self.optimizer = optimizers.SGD()\n",
    "        self.optimizer.setup(self.model)\n",
    "        self.e=e\n",
    "        self.gamma=0.95\n",
    "        self.dispPred=dispPred\n",
    "        self.last_move=None\n",
    "        self.last_board=None\n",
    "        self.last_pred=None\n",
    "        self.totalgamecount=0\n",
    "        self.rwin,self.rlose,self.rdraw,self.rmiss=1,-1,0,-1.5\n",
    "        \n",
    "    \n",
    "    def act(self,board):\n",
    "        \n",
    "        self.last_board=board.clone()\n",
    "        x=np.array([board.board],dtype=np.float32).astype(np.float32)\n",
    "        \n",
    "        pred=self.model(x)\n",
    "        if self.dispPred:print(pred.data)\n",
    "        self.last_pred=pred.data[0,:]\n",
    "        act=np.argmax(pred.data,axis=1)\n",
    "        if self.e > 0.2: #decrement epsilon over time\n",
    "            self.e -= 1/(20000)\n",
    "        if random.random() < self.e:\n",
    "            acts=board.get_possible_pos()\n",
    "            i=random.randrange(len(acts))\n",
    "            act=acts[i]\n",
    "        i=0\n",
    "        while board.board[act]!=EMPTY:\n",
    "            #print(\"Wrong Act \"+str(board.board)+\" with \"+str(act))\n",
    "            self.learn(self.last_board,act, -1, self.last_board)\n",
    "            x=np.array([board.board],dtype=np.float32).astype(np.float32)\n",
    "            pred=self.model(x)\n",
    "            #print(pred.data)\n",
    "            act=np.argmax(pred.data,axis=1)\n",
    "            i+=1\n",
    "            if i>10:\n",
    "                print(\"Exceed Pos Find\"+str(board.board)+\" with \"+str(act))\n",
    "                acts=self.last_board.get_possible_pos()\n",
    "                act=acts[random.randrange(len(acts))]\n",
    "            \n",
    "        self.last_move=act\n",
    "        #self.last_pred=pred.data[0,:]\n",
    "        return act\n",
    "    \n",
    "    def getGameResult(self,board):\n",
    "        r=0\n",
    "        if self.last_move is not None:\n",
    "            if board.winner is None:\n",
    "                self.learn(self.last_board,self.last_move, 0, board)\n",
    "                pass\n",
    "            else:\n",
    "                if board.board== self.last_board.board:            \n",
    "                    self.learn(self.last_board,self.last_move, self.rmiss, board)\n",
    "                elif board.winner == self.myturn:\n",
    "                    self.learn(self.last_board,self.last_move, self.rwin, board)\n",
    "                elif board.winner !=DRAW:\n",
    "                    self.learn(self.last_board,self.last_move, self.rlose, board)\n",
    "                else:                    #DRAW\n",
    "                    self.learn(self.last_board,self.last_move, self.rdraw, board)\n",
    "                self.totalgamecount+=1\n",
    "                self.last_move=None\n",
    "                self.last_board=None\n",
    "                self.last_pred=None\n",
    "\n",
    "    def learn(self,s,a,r,fs):\n",
    "        if fs.winner is not None:\n",
    "            maxQnew=0\n",
    "        else:\n",
    "            x=np.array([fs.board],dtype=np.float32).astype(np.float32)\n",
    "            maxQnew=np.max(self.model(x).data[0])\n",
    "        update=r+self.gamma*maxQnew\n",
    "        #print(('Prev Board:{} ,ACT:{}, Next Board:{}, Get Reward {}, Update {}').format(s.board,a,fs.board,r,update))\n",
    "        #print(('PREV:{}').format(self.last_pred))\n",
    "        self.last_pred[a]=update\n",
    "        \n",
    "        x=np.array([s.board],dtype=np.float32).astype(np.float32)\n",
    "        t=np.array([self.last_pred],dtype=np.float32).astype(np.float32)\n",
    "        self.model.zerograds()\n",
    "        loss=self.model(x,t,train=True)\n",
    "        loss.backward()\n",
    "        self.optimizer.update()\n",
    "        #print(('Updated:{}').format(self.model(x).data))\n",
    "        #print (str(s.board)+\"with \"+str(a)+\" is updated from \"+str(pQ)+\" refs MAXQ=\"+str(maxQnew)+\":\"+str(r))\n",
    "        #print(self.q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN vs AlphaRandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:69: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:51: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:52: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN:206,AlphaRandom:727,DRAW:67\n",
      "DQN:468,AlphaRandom:1406,DRAW:126\n",
      "DQN:861,AlphaRandom:1959,DRAW:180\n",
      "DQN:1458,AlphaRandom:2315,DRAW:227\n",
      "DQN:2185,AlphaRandom:2560,DRAW:255\n",
      "DQN:3022,AlphaRandom:2704,DRAW:274\n",
      "DQN:3832,AlphaRandom:2856,DRAW:312\n",
      "DQN:4632,AlphaRandom:3023,DRAW:345\n",
      "DQN:5481,AlphaRandom:3153,DRAW:366\n",
      "DQN:6326,AlphaRandom:3280,DRAW:394\n",
      "DQN:7181,AlphaRandom:3400,DRAW:419\n",
      "DQN:8032,AlphaRandom:3522,DRAW:446\n",
      "DQN:8902,AlphaRandom:3618,DRAW:480\n",
      "DQN:9791,AlphaRandom:3705,DRAW:504\n",
      "DQN:10673,AlphaRandom:3793,DRAW:534\n",
      "DQN:11545,AlphaRandom:3893,DRAW:562\n",
      "DQN:12420,AlphaRandom:3986,DRAW:594\n",
      "DQN:13300,AlphaRandom:4074,DRAW:626\n",
      "DQN:14183,AlphaRandom:4158,DRAW:659\n",
      "DQN:15058,AlphaRandom:4246,DRAW:696\n"
     ]
    }
   ],
   "source": [
    "pDQ=DQNPlayer(PLAYER_X)\n",
    "p2=PlayerAlphaRandom(PLAYER_O)\n",
    "game=TTT_GameOrganizer(pDQ,p2,20000,False,False,1000)\n",
    "game.progress()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN vs Q-Learning (Look up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:69: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:51: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:52: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN:4,QL1:436,DRAW:560\n",
      "DQN:6,QL1:790,DRAW:1204\n",
      "DQN:6,QL1:1135,DRAW:1859\n",
      "DQN:6,QL1:1472,DRAW:2522\n",
      "DQN:6,QL1:1801,DRAW:3193\n",
      "DQN:6,QL1:2123,DRAW:3871\n",
      "DQN:6,QL1:2439,DRAW:4555\n",
      "DQN:6,QL1:2777,DRAW:5217\n",
      "DQN:7,QL1:3128,DRAW:5865\n",
      "DQN:9,QL1:3648,DRAW:6343\n",
      "DQN:13,QL1:4132,DRAW:6855\n",
      "DQN:13,QL1:4606,DRAW:7381\n",
      "DQN:13,QL1:5087,DRAW:7900\n",
      "DQN:14,QL1:5536,DRAW:8450\n",
      "DQN:14,QL1:6011,DRAW:8975\n",
      "DQN:14,QL1:6496,DRAW:9490\n",
      "DQN:14,QL1:7394,DRAW:9592\n",
      "DQN:14,QL1:7925,DRAW:10061\n",
      "DQN:16,QL1:8357,DRAW:10627\n",
      "DQN:16,QL1:8777,DRAW:11207\n"
     ]
    }
   ],
   "source": [
    "#pDQ=DQNPlayer(PLAYER_X)\n",
    "pDQ.e=1\n",
    "game=TTT_GameOrganizer(pDQ,pQ,30000,False,False,1000)\n",
    "game.progress()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN vs Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:69: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:51: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:52: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O |   |   \n",
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is DQN\n",
      " O |   |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 2\n",
      " O | O |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is DQN\n",
      " O | O | X \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 7\n",
      " O | O | X \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      " O |   |   \n",
      "Turn is DQN\n",
      " O | O | X \n",
      "-----------\n",
      " X | X |   \n",
      "-----------\n",
      " O |   |   \n",
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 6\n",
      " O | O | X \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      " O |   |   \n",
      "Turn is DQN\n",
      " O | O | X \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      " O |   | X \n",
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 7\n",
      " O | O | X \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      " O |   | X \n",
      "I lost...\n",
      "Invalid Move!\n",
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 2\n",
      "   | O |   \n",
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is DQN\n",
      "   | O |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 1\n",
      " O | O |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is DQN\n",
      " O | O | X \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 7\n",
      " O | O | X \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      " O |   |   \n",
      "Turn is DQN\n",
      " O | O | X \n",
      "-----------\n",
      " X | X |   \n",
      "-----------\n",
      " O |   |   \n",
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 6\n",
      " O | O | X \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      " O |   |   \n",
      "Turn is DQN\n",
      " O | O | X \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      " O |   | X \n",
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 8\n",
      " O | O | X \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      " O | O | X \n",
      "Draw Game\n",
      "DQN:1,Human:0,DRAW:1\n"
     ]
    }
   ],
   "source": [
    "#pDQ=DQNPlayer(PLAYER_X,e=0.1)\n",
    "pDQ.e=0\n",
    "p2=PlayerHuman(PLAYER_O)\n",
    "game=TTT_GameOrganizer(pDQ,p2,2)\n",
    "game.progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
